{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# YOLOV3实现道路路面病害检测分析-paddle代码学习解析"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 一、项目说明\n",
    "本项目是用来学习飞浆框架下深度学习的实现方法，项目选用yolov3算法应用作为学习对象。项目目标目的是本着将数据处理、模型算法、模型输出、端到端布置过程都源代码实现，并提供注释说明（代码内注释说明更详细点），以便更多人能够较为全面、深入了解深度学习算法是如何工作的。由于本人对飞浆框架及众多算法理解不够，项目内容只能陆续完善，个人也是在不断的学习过程中，感兴趣的也可以自建项目完善说明。\n",
    "项目主要学习借鉴了如下课程以及相关学员的帮助指导，在此予以感谢：\n",
    "* [AI识虫比赛](https://aistudio.baidu.com/aistudio/projectdetail/3423143)\n",
    "* [百度架构师手把手带你零基础实践深度学习](https://aistudio.baidu.com/aistudio/education/group/info/1297)\n",
    "* [【全球开放数据创新应用大赛】道路路面病害智能分析baseline](https://aistudio.baidu.com/aistudio/projectdetail/2037359?channelType=0&channel=0) \n",
    "* 还有感谢飞浆资深导师毕然、讲目标检测yolov3的导师、AI达人创造营第二期班长、助教等人。\n",
    "* 特别还要说明一下，paddlex提供了非常方便的使用工具，更多的模型训练、应用部署都可推荐使用，本学习项目仅只是为了认识学习paddle环境下模型实现方法，以便于在paddlex使用时更好了灵活使用相应工具。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 二、数据说明\n",
    "* 本项目选用数据为【全球开放数据创新应用大赛】道路路面病害智能分析所提供的数据，使用者可以自行挂载相应数据。\n",
    "* 数据提供车载摄像头拍摄数据，共14000张道路病害图像样本，其中训练集提供标注标签（病害类别及目标框位置），测试集不提供标注标签。\n",
    "* 图像数据为三通道JPG图像，尺寸为1600×1184，标签COCO格式的json文件，使用utf-8编码。训练集6000张图片，测试集A榜2000张图片，测试集B榜6000张图片。\n",
    "* 对所挂数据进行解压缩，并放到指定文件夹下，具体执行如下代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open /home/aistudio/data/data93683/train.zip, /home/aistudio/data/data93683/train.zip.zip or /home/aistudio/data/data93683/train.zip.ZIP.\n",
      "unzip:  cannot find or open /home/aistudio/data/data93683/test_A.zip, /home/aistudio/data/data93683/test_A.zip.zip or /home/aistudio/data/data93683/test_A.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "# Way_One:\n",
    "!unzip -oq /home/aistudio/data/data93683/train.zip -d dataset\n",
    "!unzip -oq /home/aistudio/data/data93683/test_A.zip -d dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 三、数据处理"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### trainsiton.py\n",
    "1. 主要实现将解压缩后的数据集生成标签文件和图片，路径根据实际情况自己修改\n",
    "2. 需要安装相应的依赖库，包括cocoapi、pycocotools、lxml\n",
    "3. 在dataset文件夹下建立VOC文件夹，可以在左侧手动建立文件夹，也可以通过如下代码建立文件夹，生成VOC文件夹后要将路径修改为默认根路径\n",
    "4. 接下来就可以执行transition.py了，执行时要注意查看对应路径是否正确。代码会执行生成标签文件和图片。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/var/cache/buildkit/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://mirror.baidu.com/pypi/simple, http://192.168.1.10:7104/test/pypi/\n",
      "Requirement already satisfied: pycocotools in /home/vscode/.local/lib/python3.10/site-packages (2.0.6)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /home/vscode/.local/lib/python3.10/site-packages (from pycocotools) (3.7.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pycocotools) (1.24.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/vscode/.local/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/vscode/.local/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/vscode/.local/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/vscode/.local/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/vscode/.local/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/vscode/.local/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\n",
      "[Errno 2] No such file or directory: 'cocoapi/PythonAPI/'\n",
      "/workspaces/roadai/yolov3_raod_detect\n",
      "make: *** No targets specified and no makefile found.  Stop.\n",
      "python: can't open file '/workspaces/roadai/yolov3_raod_detect/setup.py': [Errno 2] No such file or directory\n",
      "\u001b[33mWARNING: The directory '/var/cache/buildkit/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: http://pypi.mirrors.ustc.edu.cn/simple/, http://192.168.1.10:7104/test/pypi/\n",
      "Requirement already satisfied: lxml in /home/vscode/.local/lib/python3.10/site-packages (4.9.2)\n"
     ]
    }
   ],
   "source": [
    "# !git clone git@github.com:cocodataset/cocoapi.git\n",
    "!pip install pycocotools -i https://mirror.baidu.com/pypi/simple\n",
    "%cd cocoapi/PythonAPI/\n",
    "!make\n",
    "!python setup.py install\n",
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'dataset/'\n",
      "/workspaces/roadai/yolov3_raod_detect\n",
      "mkdir: cannot create directory ‘VOC’: File exists\n",
      "[Errno 2] No such file or directory: '/home/aistudio/'\n",
      "/workspaces/roadai/yolov3_raod_detect\n"
     ]
    }
   ],
   "source": [
    "%cd dataset/\n",
    "!mkdir VOC\n",
    "%cd /home/aistudio/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/roadai/yolov3_raod_detect/transition.py\", line 121, in <module>\n",
      "    main()\n",
      "  File \"/workspaces/roadai/yolov3_raod_detect/transition.py\", line 113, in main\n",
      "    mkr(image_dir)\n",
      "  File \"/workspaces/roadai/yolov3_raod_detect/transition.py\", line 16, in mkr\n",
      "    os.mkdir(path)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './dataset/VOC/JPEGImages'\n"
     ]
    }
   ],
   "source": [
    "!python transition.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### insects_reader.py\n",
    "* 主要实现读取图片路径信息，标签信息等\n",
    "* 文件可以独立执行，执行结果是打印出来records记录中的第八个数据，信息包括图片路径、id、长、宽、分类标签gt_calss、标识框gt_bbox等等\n",
    "* 注意records记录是打乱顺序的，所以records[8]并不代表第八张图片的信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/roadai/yolov3_raod_detect/insects_reader.py\", line 86, in <module>\n",
      "    records = get_annotations(cname2cid, datadir)\n",
      "  File \"/workspaces/roadai/yolov3_raod_detect/insects_reader.py\", line 28, in get_annotations\n",
      "    filenames = os.listdir(os.path.join(datadir, 'Annotations'))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './dataset/VOC/Annotations'\n"
     ]
    }
   ],
   "source": [
    "!python insects_reader.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### reader.py\n",
    "* reader.py引用了insects_reader.py、image_utils.py文件。\n",
    "* 其中insects_reader.py是读取图像、标签等信息，如上所述；\n",
    "* image_utils.py则是图像增广处理，具体请看源代码中注释，通常用户可以根据自己项目添加设置图像预处理方式。\n",
    "* image_utils.py文件中引用了box_utils.py文件，该文件有三个函数，分别为计算xyxy形式框的IOU、计算xywh形式框的IOU、批量计算IOU、。。。\n",
    "* 文件可以单独执行，输出img、gt_box、gt_lables的数据格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Can not import paddle core while this file exists: /home/vscode/.local/lib/python3.10/site-packages/paddle/fluid/libpaddle.so\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/roadai/yolov3_raod_detect/reader.py\", line 8, in <module>\n",
      "    import paddle\n",
      "  File \"/home/vscode/.local/lib/python3.10/site-packages/paddle/__init__.py\", line 31, in <module>\n",
      "    from .framework import monkey_patch_variable\n",
      "  File \"/home/vscode/.local/lib/python3.10/site-packages/paddle/framework/__init__.py\", line 17, in <module>\n",
      "    from . import random  # noqa: F401\n",
      "  File \"/home/vscode/.local/lib/python3.10/site-packages/paddle/framework/random.py\", line 17, in <module>\n",
      "    from paddle import fluid\n",
      "  File \"/home/vscode/.local/lib/python3.10/site-packages/paddle/fluid/__init__.py\", line 36, in <module>\n",
      "    from . import framework\n",
      "  File \"/home/vscode/.local/lib/python3.10/site-packages/paddle/fluid/framework.py\", line 35, in <module>\n",
      "    from . import core\n",
      "  File \"/home/vscode/.local/lib/python3.10/site-packages/paddle/fluid/core.py\", line 356, in <module>\n",
      "    raise e\n",
      "  File \"/home/vscode/.local/lib/python3.10/site-packages/paddle/fluid/core.py\", line 269, in <module>\n",
      "    from . import libpaddle\n",
      "ImportError: libssl.so.1.1: cannot open shared object file: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python reader.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### draw_anchors.py\n",
    "draw_anchors.py是实现在图片上标注锚框，提供了测试图片，感兴趣的可以调整数据参数后再执行文件，便于直观理解。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/roadai/yolov3_raod_detect/draw_anchors.py\", line 48, in <module>\n",
      "    im = imread(filename)\n",
      "  File \"/home/vscode/.local/lib/python3.10/site-packages/matplotlib/image.py\", line 1563, in imread\n",
      "    with img_open(fname) as image:\n",
      "  File \"/home/vscode/.local/lib/python3.10/site-packages/PIL/Image.py\", line 3218, in open\n",
      "    fp = builtins.open(filename, \"rb\")\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './dataset/VOC/JPEGImages/00100.jpg'\n"
     ]
    }
   ],
   "source": [
    "!python draw_anchors.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### anchor_lables.py\n",
    "* 前面的draw_anchors.py是给了一个一张图片，固定设置锚框大小尺寸，然后打印出来，而anchor_lables.py则是调用图像集和标签信息来计算锚框的标签信息。\n",
    "* 注意我的平台不能用multithread_loader，只能使用data_loader来读取加载图片信息。\n",
    "* 执行文件会打印出来所有图片的数据结构。都标注出了objectness为正的预测框，剩下的预测框则默认objectness为0，对于objectness为1的预测框，标出了他们所包含的物体类别，以及位置回归的目标，scale_location用来调节不同尺寸的锚框对损失函数的贡献，作为加权系数和位置损失函数相乘。\n",
    "* 给出的应该是p0层的锚框输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Can not import paddle core while this file exists: /home/vscode/.local/lib/python3.10/site-packages/paddle/fluid/libpaddle.so\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/roadai/yolov3_raod_detect/anchor_lables.py\", line 4, in <module>\n",
      "    from reader import multithread_loader, data_loader\n",
      "  File \"/workspaces/roadai/yolov3_raod_detect/reader.py\", line 8, in <module>\n",
      "    import paddle\n",
      "  File \"/home/vscode/.local/lib/python3.10/site-packages/paddle/__init__.py\", line 31, in <module>\n",
      "    from .framework import monkey_patch_variable\n",
      "  File \"/home/vscode/.local/lib/python3.10/site-packages/paddle/framework/__init__.py\", line 17, in <module>\n",
      "    from . import random  # noqa: F401\n",
      "  File \"/home/vscode/.local/lib/python3.10/site-packages/paddle/framework/random.py\", line 17, in <module>\n",
      "    from paddle import fluid\n",
      "  File \"/home/vscode/.local/lib/python3.10/site-packages/paddle/fluid/__init__.py\", line 36, in <module>\n",
      "    from . import framework\n",
      "  File \"/home/vscode/.local/lib/python3.10/site-packages/paddle/fluid/framework.py\", line 35, in <module>\n",
      "    from . import core\n",
      "  File \"/home/vscode/.local/lib/python3.10/site-packages/paddle/fluid/core.py\", line 356, in <module>\n",
      "    raise e\n",
      "  File \"/home/vscode/.local/lib/python3.10/site-packages/paddle/fluid/core.py\", line 269, in <module>\n",
      "    from . import libpaddle\n",
      "ImportError: libssl.so.1.1: cannot open shared object file: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python anchor_lables.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 锚框大小选择和图像均值参数选择问题\n",
    "* 可能很多人在执行yolov3模型时，都选用昆虫项目案例中的mean = [0.485, 0.456, 0.406]，std = [0.229, 0.224, 0.225]，如下代码给出了均值和方差选择的一种方法；\n",
    "* 锚框大小选择问题，目前我依然不太清楚怎么处理。在此前项目执行时采用昆虫项目给出的锚框，此前训练200轮，损失函数最终只到4左右，模型输出预测，还比较准。感兴趣的可以执行试试看，模型为yolo_epoch199.pdparams。\n",
    "* 代码给出的锚框如下，三层分别使用对应的锚框大小。ANCHORS = [10, 13, 16, 30, 33, 23, 30, 61, 62, 45, 59, 119, 116, 90, 156, 198, 373, 326]，ANCHOR_MASKS = [[6, 7, 8], [3, 4, 5], [0, 1, 2]],每层3个锚框。\n",
    "* 飞浆成员“白鱼”在其路面情况检测项目中，给出的锚框选择貌似是[320, 352, 384, 416, 448, 480, 512, 544, 576, 608]，五组锚框，但是不知是哪一层的？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 0\n",
      "mean: [nan nan nan]\n",
      "std: [nan nan nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43857/1633810673.py:17: RuntimeWarning: invalid value encountered in divide\n",
      "  mean /= len(image_path_list)\n",
      "/tmp/ipykernel_43857/1633810673.py:18: RuntimeWarning: invalid value encountered in divide\n",
      "  std /= len(image_path_list)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def get_mean_std(image_path_list):\n",
    "    print('Total images:', len(image_path_list))\n",
    "    max_val, min_val = np.zeros(3), np.ones(3) * 255\n",
    "    mean, std = np.zeros(3), np.zeros(3)\n",
    "    for image_path in image_path_list:\n",
    "        image = cv2.imread(image_path)\n",
    "        for c in range(3):\n",
    "            mean[c] += image[:, :, c].mean()\n",
    "            std[c] += image[:, :, c].std()\n",
    "            max_val[c] = max(max_val[c], image[:, :, c].max())\n",
    "            min_val[c] = min(min_val[c], image[:, :, c].min())\n",
    "\n",
    "    mean /= len(image_path_list)\n",
    "    std /= len(image_path_list)\n",
    "\n",
    "    mean /= max_val - min_val\n",
    "    std /= max_val - min_val\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "mean, std = get_mean_std(glob.glob('./dataset/VOC/JPEGImages/*.jpg'))\n",
    "print('mean:', mean)\n",
    "print('std:', std)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 四、模型选择\n",
    "YOLOv3算法的基本思想可以分成两部分：\n",
    "* 按一定规则在图片上产生一系列的候选区域，然后根据这些候选区域与图片上物体真实框之间的位置关系对候选区域进行标注。跟真实框足够接近的那些候选区域会被标注为正样本，同时将真实框的位置作为正样本的位置目标。偏离真实框较大的那些候选区域则会被标注为负样本，负样本不需要预测位置或者类别。\n",
    "* 使用卷积神经网络提取图片特征并对候选区域的位置和类别进行预测。这样每个预测框就可以看成是一个样本，根据真实框相对它的位置和类别进行了标注而获得标签值，通过网络模型预测其位置和类别，将网络预测值和标签值进行比较，就可以建立起损失函数。\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/0f64b7c6e82445849b4f81bc77f4b11551f4a22209fd4af4b2858fbad9647b5f)\n",
    "\n",
    "* 左边是输入图片，上半部分所示的过程是使用卷积神经网络对图片提取特征，随着网络不断向前传播，特征图的尺寸越来越小，每个像素点会代表更加抽象的特征模式，直到输出特征图，其尺寸减小为原图的1/32。\n",
    "* 下半部分描述了生成候选区域的过程，首先将原图划分成多个小方块，每个小方块的大小是32×32，然后以每个小方块为中心分别生成一系列锚框，整张图片都会被锚框覆盖到。在每个锚框的基础上产生一个与之对应的预测框，根据锚框和预测框与图片上物体真实框之间的位置关系，对这些预测框进行标注。\n",
    "* 将上方支路中输出的特征图与下方支路中产生的预测框标签建立关联，创建损失函数，开启端到端的训练过程。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### yolov3.py\n",
    "* YOLOv3(paddle.nn.Layer)类，初始化的时候，道路检测的类别是8个，这个地方对num_classes进行了修改；\n",
    "* 飞桨给出的计算p0、p1、p2层的损失函数的函数为paddle.vision.ops.yolo_loss；\n",
    "* 为便于理解yolov算法，提供了p0层的损失函数计算并打印看看运行效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Can not import paddle core while this file exists: /home/vscode/.local/lib/python3.10/site-packages/paddle/fluid/libpaddle.so\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/roadai/yolov3_raod_detect/yolov3.py\", line 6, in <module>\n",
      "    import paddle\n",
      "  File \"/home/vscode/.local/lib/python3.10/site-packages/paddle/__init__.py\", line 31, in <module>\n",
      "    from .framework import monkey_patch_variable\n",
      "  File \"/home/vscode/.local/lib/python3.10/site-packages/paddle/framework/__init__.py\", line 17, in <module>\n",
      "    from . import random  # noqa: F401\n",
      "  File \"/home/vscode/.local/lib/python3.10/site-packages/paddle/framework/random.py\", line 17, in <module>\n",
      "    from paddle import fluid\n",
      "  File \"/home/vscode/.local/lib/python3.10/site-packages/paddle/fluid/__init__.py\", line 36, in <module>\n",
      "    from . import framework\n",
      "  File \"/home/vscode/.local/lib/python3.10/site-packages/paddle/fluid/framework.py\", line 35, in <module>\n",
      "    from . import core\n",
      "  File \"/home/vscode/.local/lib/python3.10/site-packages/paddle/fluid/core.py\", line 356, in <module>\n",
      "    raise e\n",
      "  File \"/home/vscode/.local/lib/python3.10/site-packages/paddle/fluid/core.py\", line 269, in <module>\n",
      "    from . import libpaddle\n",
      "ImportError: libssl.so.1.1: cannot open shared object file: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python yolov3.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### train.py\n",
    "* 可以使用paddle.io.DataLoader创建数据读取器，并设置batchsize，进程数量num_workers等参数，实现多进程读取数据，但试了本地CPU环境不能用。\n",
    "* 也可以使用自带data_loader函数读取数据，设置batchsize，但只能单进程执行，暂不能执行多进程multithread_loader，原因是自己对相应调用的函数还没理解。\n",
    "使用paddle自带的paddle.vision.ops.yolo_loss，直接计算p0、p1、p2层损失函数，过程更简洁，速度也更快"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Can not import paddle core while this file exists: /home/vscode/.local/lib/python3.10/site-packages/paddle/fluid/libpaddle.so\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/roadai/yolov3_raod_detect/train.py\", line 6, in <module>\n",
      "    import paddle\n",
      "  File \"/home/vscode/.local/lib/python3.10/site-packages/paddle/__init__.py\", line 31, in <module>\n",
      "    from .framework import monkey_patch_variable\n",
      "  File \"/home/vscode/.local/lib/python3.10/site-packages/paddle/framework/__init__.py\", line 17, in <module>\n",
      "    from . import random  # noqa: F401\n",
      "  File \"/home/vscode/.local/lib/python3.10/site-packages/paddle/framework/random.py\", line 17, in <module>\n",
      "    from paddle import fluid\n",
      "  File \"/home/vscode/.local/lib/python3.10/site-packages/paddle/fluid/__init__.py\", line 36, in <module>\n",
      "    from . import framework\n",
      "  File \"/home/vscode/.local/lib/python3.10/site-packages/paddle/fluid/framework.py\", line 35, in <module>\n",
      "    from . import core\n",
      "  File \"/home/vscode/.local/lib/python3.10/site-packages/paddle/fluid/core.py\", line 356, in <module>\n",
      "    raise e\n",
      "  File \"/home/vscode/.local/lib/python3.10/site-packages/paddle/fluid/core.py\", line 269, in <module>\n",
      "    from . import libpaddle\n",
      "ImportError: libssl.so.1.1: cannot open shared object file: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python train.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 模型导出inference\n",
    "* 模型导出采用paddle.jit.save保存为静态模式，执行的结果我们可以看出生成了inference文件夹，里面保存了存储的模型结构 Program 文件的后缀为 .pdmodel ，存储的持久参数变量文件的后缀为 .pdiparams ，同时这里也会将一些变量描述信息存储至文件，文件后缀为 .pdiparams.info。\n",
    "* paddle2.0之后也提供了save_inference_model进行动静转化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-12.1/NsightSystems-cli-2023.2.3/host-linux-x64/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: Can not import paddle core while this file exists: /home/vscode/.local/lib/python3.10/site-packages/paddle/fluid/libpaddle.so\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "libssl.so.1.1: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# save inference model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpaddle\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39myolov3\u001b[39;00m \u001b[39mimport\u001b[39;00m YOLOv3\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpaddle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstatic\u001b[39;00m \u001b[39mimport\u001b[39;00m InputSpec\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/paddle/__init__.py:31\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbatch\u001b[39;00m \u001b[39mimport\u001b[39;00m batch  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[39m# Do the *DUPLICATED* monkey-patch for the tensor object.\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[39m# We need remove the duplicated code here once we fix\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39m# the illogical implement in the monkey-patch methods later.\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m monkey_patch_variable\n\u001b[1;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m monkey_patch_math_tensor\n\u001b[1;32m     34\u001b[0m monkey_patch_variable()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/paddle/framework/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#   Copyright (c) 2020 PaddlePaddle Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[39m# TODO: import framework api under this directory\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m random  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mrandom\u001b[39;00m \u001b[39mimport\u001b[39;00m seed  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m get_default_dtype  \u001b[39m# noqa: F401\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/paddle/framework/random.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#   Copyright (c) 2020 PaddlePaddle Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[39m# TODO: define random api\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpaddle\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpaddle\u001b[39;00m \u001b[39mimport\u001b[39;00m fluid\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpaddle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfluid\u001b[39;00m \u001b[39mimport\u001b[39;00m core\n\u001b[1;32m     20\u001b[0m __all__ \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/paddle/fluid/__init__.py:36\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m     35\u001b[0m \u001b[39m# import all class inside framework into fluid module\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m framework\n\u001b[1;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m     39\u001b[0m \u001b[39m# import all class inside executor into fluid module\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/paddle/fluid/framework.py:35\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlogging\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mproto\u001b[39;00m \u001b[39mimport\u001b[39;00m framework_pb2, data_feed_pb2\n\u001b[0;32m---> 35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m core\n\u001b[1;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m unique_name\n\u001b[1;32m     37\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpaddle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mversion\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mfluid_version\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/paddle/fluid/core.py:356\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m avx_supported() \u001b[39mand\u001b[39;00m libpaddle\u001b[39m.\u001b[39mis_compiled_with_avx():\n\u001b[1;32m    352\u001b[0m         sys\u001b[39m.\u001b[39mstderr\u001b[39m.\u001b[39mwrite(\n\u001b[1;32m    353\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mError: Your machine doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt support AVX, but the installed PaddlePaddle is avx core, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    354\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myou should reinstall paddlepaddle with no-avx core.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    355\u001b[0m         )\n\u001b[0;32m--> 356\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    359\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_paddle_custom_device_lib_path\u001b[39m(lib_path):\n\u001b[1;32m    360\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39menviron\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mCUSTOM_DEVICE_ROOT\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    361\u001b[0m         \u001b[39m# use setted environment value\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/paddle/fluid/core.py:269\u001b[0m\n\u001b[1;32m    266\u001b[0m             sys\u001b[39m.\u001b[39mstderr\u001b[39m.\u001b[39mwrite(\u001b[39m'\u001b[39m\u001b[39mError: Can not preload libgomp.so\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    268\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 269\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m libpaddle\n\u001b[1;32m    271\u001b[0m     \u001b[39mif\u001b[39;00m avx_supported() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m libpaddle\u001b[39m.\u001b[39mis_compiled_with_avx():\n\u001b[1;32m    272\u001b[0m         sys\u001b[39m.\u001b[39mstderr\u001b[39m.\u001b[39mwrite(\n\u001b[1;32m    273\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mHint: Your machine support AVX, but the installed paddlepaddle doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt have avx core. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mHence, no-avx core with worse performance will be imported.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mIf you like, you could \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    275\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mreinstall paddlepaddle by \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpython -m pip install --force-reinstall paddlepaddle-gpu[==version]\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    276\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mto get better performance.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    277\u001b[0m         )\n",
      "\u001b[0;31mImportError\u001b[0m: libssl.so.1.1: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "# save inference model\n",
    "import paddle\n",
    "from yolov3 import YOLOv3\n",
    "from paddle.static import InputSpec\n",
    "#\n",
    "model = YOLOv3(num_classes=8)\n",
    "# 加载训练好的模型参数\n",
    "state_dict = paddle.load(\"./yolo_epoch199.pdparams\")\n",
    "# 将训练好的参数读取到网络中\n",
    "model.set_state_dict(state_dict)\n",
    "# 设置模型为评估模式\n",
    "model.eval()\n",
    "\n",
    "# 保存inference模型\n",
    "paddle.jit.save(\n",
    "    layer=model,\n",
    "    path=\"inference/model\",\n",
    "    input_spec=[InputSpec(shape=[1, 3, 640, 640], dtype='float32')]\n",
    ")\n",
    "\n",
    "print(\"==>Inference model saved in inference\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 五、模型评估"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### predict_all.py\n",
    "* 下面是完整的测试程序，在测试数据集上的输出结果将会被保存在pred_results.json文件中。\n",
    "* 预测框列表中每个元素[label, score, x1, y1, x2, y2]描述了一个预测框，label是预测框所属类别标签，score是预测框的得分；x1, y1, x2, y2对应预测框左上角坐标(x1, y1)，右下角坐标(x2, y2)。每张图片可能有很多个预测框，则将其全部放在预测框列表中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0705 11:17:21.810673  1228 device_context.cc:404] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 10.1\n",
      "W0705 11:17:21.815260  1228 device_context.cc:422] device: 0, cuDNN Version: 7.6.\n",
      "predict_all.py:52: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if result_j != []:\n",
      "processed 1 pictures\n",
      "processed 2 pictures\n",
      "processed 3 pictures\n",
      "processed 4 pictures\n",
      "processed 5 pictures\n",
      "processed 6 pictures\n",
      "processed 7 pictures\n",
      "processed 8 pictures\n",
      "processed 9 pictures\n",
      "processed 10 pictures\n",
      "processed 11 pictures\n",
      "processed 12 pictures\n",
      "processed 13 pictures\n",
      "processed 14 pictures\n",
      "processed 15 pictures\n",
      "processed 16 pictures\n",
      "processed 17 pictures\n",
      "processed 18 pictures\n",
      "processed 19 pictures\n",
      "processed 20 pictures\n",
      "processed 21 pictures\n",
      "processed 22 pictures\n",
      "processed 23 pictures\n",
      "processed 24 pictures\n",
      "processed 25 pictures\n",
      "processed 26 pictures\n",
      "processed 27 pictures\n",
      "processed 28 pictures\n",
      "processed 29 pictures\n",
      "processed 30 pictures\n",
      "processed 31 pictures\n",
      "processed 32 pictures\n",
      "processed 33 pictures\n",
      "processed 34 pictures\n",
      "processed 35 pictures\n",
      "processed 36 pictures\n",
      "processed 37 pictures\n",
      "processed 38 pictures\n",
      "processed 39 pictures\n",
      "processed 40 pictures\n",
      "processed 41 pictures\n",
      "processed 42 pictures\n",
      "processed 43 pictures\n",
      "processed 44 pictures\n",
      "processed 45 pictures\n",
      "processed 46 pictures\n",
      "processed 47 pictures\n",
      "processed 48 pictures\n",
      "processed 49 pictures\n",
      "processed 50 pictures\n",
      "processed 51 pictures\n",
      "processed 52 pictures\n",
      "processed 53 pictures\n",
      "processed 54 pictures\n",
      "processed 55 pictures\n",
      "processed 56 pictures\n",
      "processed 57 pictures\n",
      "processed 58 pictures\n",
      "processed 59 pictures\n",
      "processed 60 pictures\n",
      "processed 61 pictures\n",
      "processed 62 pictures\n",
      "processed 63 pictures\n",
      "processed 64 pictures\n",
      "processed 65 pictures\n",
      "processed 66 pictures\n",
      "processed 67 pictures\n",
      "processed 68 pictures\n",
      "processed 69 pictures\n",
      "processed 70 pictures\n",
      "processed 71 pictures\n",
      "processed 72 pictures\n",
      "processed 73 pictures\n",
      "processed 74 pictures\n",
      "processed 75 pictures\n",
      "processed 76 pictures\n",
      "processed 77 pictures\n",
      "processed 78 pictures\n",
      "processed 79 pictures\n",
      "processed 80 pictures\n",
      "processed 81 pictures\n",
      "processed 82 pictures\n",
      "processed 83 pictures\n",
      "processed 84 pictures\n",
      "processed 85 pictures\n",
      "processed 86 pictures\n",
      "processed 87 pictures\n",
      "processed 88 pictures\n",
      "processed 89 pictures\n",
      "processed 90 pictures\n",
      "processed 91 pictures\n",
      "processed 92 pictures\n",
      "processed 93 pictures\n",
      "processed 94 pictures\n",
      "processed 95 pictures\n",
      "processed 96 pictures\n",
      "processed 97 pictures\n",
      "processed 98 pictures\n",
      "processed 99 pictures\n",
      "processed 100 pictures\n",
      "processed 101 pictures\n",
      "processed 102 pictures\n",
      "processed 103 pictures\n",
      "processed 104 pictures\n",
      "processed 105 pictures\n",
      "processed 106 pictures\n",
      "processed 107 pictures\n",
      "processed 108 pictures\n",
      "processed 109 pictures\n",
      "processed 110 pictures\n",
      "processed 111 pictures\n",
      "processed 112 pictures\n",
      "processed 113 pictures\n",
      "processed 114 pictures\n",
      "processed 115 pictures\n",
      "processed 116 pictures\n",
      "processed 117 pictures\n",
      "processed 118 pictures\n",
      "processed 119 pictures\n",
      "processed 120 pictures\n",
      "processed 121 pictures\n",
      "processed 122 pictures\n",
      "processed 123 pictures\n",
      "processed 124 pictures\n",
      "processed 125 pictures\n",
      "processed 126 pictures\n",
      "processed 127 pictures\n",
      "processed 128 pictures\n",
      "processed 129 pictures\n",
      "processed 130 pictures\n",
      "processed 131 pictures\n",
      "processed 132 pictures\n",
      "processed 133 pictures\n",
      "processed 134 pictures\n",
      "processed 135 pictures\n",
      "processed 136 pictures\n",
      "processed 137 pictures\n",
      "processed 138 pictures\n",
      "processed 139 pictures\n",
      "processed 140 pictures\n",
      "processed 141 pictures\n",
      "processed 142 pictures\n",
      "processed 143 pictures\n",
      "processed 144 pictures\n",
      "processed 145 pictures\n",
      "processed 146 pictures\n",
      "processed 147 pictures\n",
      "processed 148 pictures\n",
      "processed 149 pictures\n",
      "processed 150 pictures\n",
      "processed 151 pictures\n",
      "processed 152 pictures\n",
      "processed 153 pictures\n",
      "processed 154 pictures\n",
      "processed 155 pictures\n",
      "processed 156 pictures\n",
      "processed 157 pictures\n",
      "processed 158 pictures\n",
      "processed 159 pictures\n",
      "processed 160 pictures\n",
      "processed 161 pictures\n",
      "processed 162 pictures\n",
      "processed 163 pictures\n",
      "processed 164 pictures\n",
      "processed 165 pictures\n",
      "processed 166 pictures\n",
      "processed 167 pictures\n",
      "processed 168 pictures\n",
      "processed 169 pictures\n",
      "processed 170 pictures\n",
      "processed 171 pictures\n",
      "processed 172 pictures\n",
      "processed 173 pictures\n",
      "processed 174 pictures\n",
      "processed 175 pictures\n",
      "processed 176 pictures\n",
      "processed 177 pictures\n",
      "processed 178 pictures\n",
      "processed 179 pictures\n",
      "processed 180 pictures\n",
      "processed 181 pictures\n",
      "processed 182 pictures\n",
      "processed 183 pictures\n",
      "processed 184 pictures\n",
      "processed 185 pictures\n",
      "processed 186 pictures\n",
      "processed 187 pictures\n",
      "processed 188 pictures\n",
      "processed 189 pictures\n",
      "processed 190 pictures\n",
      "processed 191 pictures\n",
      "processed 192 pictures\n",
      "processed 193 pictures\n",
      "processed 194 pictures\n",
      "processed 195 pictures\n",
      "processed 196 pictures\n",
      "processed 197 pictures\n",
      "processed 198 pictures\n",
      "processed 199 pictures\n",
      "processed 200 pictures\n",
      "processed 201 pictures\n",
      "processed 202 pictures\n",
      "processed 203 pictures\n",
      "processed 204 pictures\n",
      "processed 205 pictures\n",
      "processed 206 pictures\n",
      "processed 207 pictures\n",
      "processed 208 pictures\n",
      "processed 209 pictures\n",
      "processed 210 pictures\n",
      "processed 211 pictures\n",
      "processed 212 pictures\n",
      "processed 213 pictures\n",
      "processed 214 pictures\n",
      "processed 215 pictures\n",
      "processed 216 pictures\n",
      "processed 217 pictures\n",
      "processed 218 pictures\n",
      "processed 219 pictures\n",
      "processed 220 pictures\n",
      "processed 221 pictures\n",
      "processed 222 pictures\n",
      "processed 223 pictures\n",
      "processed 224 pictures\n",
      "processed 225 pictures\n",
      "processed 226 pictures\n",
      "processed 227 pictures\n",
      "processed 228 pictures\n",
      "processed 229 pictures\n",
      "processed 230 pictures\n",
      "processed 231 pictures\n",
      "processed 232 pictures\n",
      "processed 233 pictures\n",
      "processed 234 pictures\n",
      "processed 235 pictures\n",
      "processed 236 pictures\n",
      "processed 237 pictures\n",
      "processed 238 pictures\n",
      "processed 239 pictures\n",
      "processed 240 pictures\n",
      "processed 241 pictures\n",
      "processed 242 pictures\n",
      "processed 243 pictures\n",
      "processed 244 pictures\n",
      "processed 245 pictures\n",
      "processed 246 pictures\n",
      "processed 247 pictures\n",
      "processed 248 pictures\n",
      "processed 249 pictures\n",
      "processed 250 pictures\n",
      "processed 251 pictures\n",
      "processed 252 pictures\n",
      "processed 253 pictures\n",
      "processed 254 pictures\n",
      "processed 255 pictures\n",
      "processed 256 pictures\n",
      "processed 257 pictures\n",
      "processed 258 pictures\n",
      "processed 259 pictures\n",
      "processed 260 pictures\n",
      "processed 261 pictures\n",
      "processed 262 pictures\n",
      "processed 263 pictures\n",
      "processed 264 pictures\n",
      "processed 265 pictures\n",
      "processed 266 pictures\n",
      "processed 267 pictures\n",
      "processed 268 pictures\n",
      "processed 269 pictures\n",
      "processed 270 pictures\n",
      "processed 271 pictures\n",
      "processed 272 pictures\n",
      "processed 273 pictures\n",
      "processed 274 pictures\n",
      "processed 275 pictures\n",
      "processed 276 pictures\n",
      "processed 277 pictures\n",
      "processed 278 pictures\n",
      "processed 279 pictures\n",
      "processed 280 pictures\n",
      "processed 281 pictures\n",
      "processed 282 pictures\n",
      "processed 283 pictures\n",
      "processed 284 pictures\n",
      "processed 285 pictures\n",
      "processed 286 pictures\n",
      "processed 287 pictures\n",
      "processed 288 pictures\n",
      "processed 289 pictures\n",
      "processed 290 pictures\n",
      "processed 291 pictures\n",
      "processed 292 pictures\n",
      "processed 293 pictures\n",
      "processed 294 pictures\n",
      "processed 295 pictures\n",
      "processed 296 pictures\n",
      "processed 297 pictures\n",
      "processed 298 pictures\n",
      "processed 299 pictures\n",
      "processed 300 pictures\n",
      "processed 301 pictures\n",
      "processed 302 pictures\n",
      "processed 303 pictures\n",
      "processed 304 pictures\n",
      "processed 305 pictures\n",
      "processed 306 pictures\n",
      "processed 307 pictures\n",
      "processed 308 pictures\n",
      "processed 309 pictures\n",
      "processed 310 pictures\n",
      "processed 311 pictures\n",
      "processed 312 pictures\n",
      "processed 313 pictures\n",
      "processed 314 pictures\n",
      "processed 315 pictures\n",
      "processed 316 pictures\n",
      "processed 317 pictures\n",
      "processed 318 pictures\n",
      "processed 319 pictures\n",
      "processed 320 pictures\n",
      "processed 321 pictures\n",
      "processed 322 pictures\n",
      "processed 323 pictures\n",
      "processed 324 pictures\n",
      "processed 325 pictures\n",
      "processed 326 pictures\n",
      "processed 327 pictures\n",
      "processed 328 pictures\n",
      "processed 329 pictures\n",
      "processed 330 pictures\n",
      "processed 331 pictures\n",
      "processed 332 pictures\n",
      "processed 333 pictures\n",
      "processed 334 pictures\n",
      "processed 335 pictures\n",
      "processed 336 pictures\n",
      "processed 337 pictures\n",
      "processed 338 pictures\n",
      "processed 339 pictures\n",
      "processed 340 pictures\n",
      "processed 341 pictures\n",
      "processed 342 pictures\n",
      "processed 343 pictures\n",
      "processed 344 pictures\n",
      "processed 345 pictures\n",
      "processed 346 pictures\n",
      "processed 347 pictures\n",
      "processed 348 pictures\n",
      "processed 349 pictures\n",
      "processed 350 pictures\n",
      "processed 351 pictures\n",
      "processed 352 pictures\n",
      "processed 353 pictures\n",
      "processed 354 pictures\n",
      "processed 355 pictures\n",
      "processed 356 pictures\n",
      "processed 357 pictures\n",
      "processed 358 pictures\n",
      "processed 359 pictures\n",
      "processed 360 pictures\n",
      "processed 361 pictures\n",
      "processed 362 pictures\n",
      "processed 363 pictures\n",
      "processed 364 pictures\n",
      "processed 365 pictures\n",
      "processed 366 pictures\n",
      "processed 367 pictures\n",
      "processed 368 pictures\n",
      "processed 369 pictures\n",
      "processed 370 pictures\n",
      "processed 371 pictures\n",
      "processed 372 pictures\n",
      "processed 373 pictures\n",
      "processed 374 pictures\n",
      "processed 375 pictures\n",
      "processed 376 pictures\n",
      "processed 377 pictures\n",
      "processed 378 pictures\n",
      "processed 379 pictures\n",
      "processed 380 pictures\n",
      "processed 381 pictures\n",
      "processed 382 pictures\n",
      "processed 383 pictures\n",
      "processed 384 pictures\n",
      "processed 385 pictures\n",
      "processed 386 pictures\n",
      "processed 387 pictures\n",
      "processed 388 pictures\n",
      "processed 389 pictures\n",
      "processed 390 pictures\n",
      "processed 391 pictures\n",
      "processed 392 pictures\n",
      "processed 393 pictures\n",
      "processed 394 pictures\n",
      "processed 395 pictures\n",
      "processed 396 pictures\n",
      "processed 397 pictures\n",
      "processed 398 pictures\n",
      "processed 399 pictures\n",
      "processed 400 pictures\n",
      "processed 401 pictures\n",
      "processed 402 pictures\n",
      "processed 403 pictures\n",
      "processed 404 pictures\n",
      "processed 405 pictures\n",
      "processed 406 pictures\n",
      "processed 407 pictures\n",
      "processed 408 pictures\n",
      "processed 409 pictures\n",
      "processed 410 pictures\n",
      "processed 411 pictures\n",
      "processed 412 pictures\n",
      "processed 413 pictures\n",
      "processed 414 pictures\n",
      "processed 415 pictures\n",
      "processed 416 pictures\n",
      "processed 417 pictures\n",
      "processed 418 pictures\n",
      "processed 419 pictures\n",
      "processed 420 pictures\n",
      "processed 421 pictures\n",
      "processed 422 pictures\n",
      "processed 423 pictures\n",
      "processed 424 pictures\n",
      "processed 425 pictures\n",
      "processed 426 pictures\n",
      "processed 427 pictures\n",
      "processed 428 pictures\n",
      "processed 429 pictures\n",
      "processed 430 pictures\n",
      "processed 431 pictures\n",
      "processed 432 pictures\n",
      "processed 433 pictures\n",
      "processed 434 pictures\n",
      "processed 435 pictures\n",
      "processed 436 pictures\n",
      "processed 437 pictures\n",
      "processed 438 pictures\n",
      "processed 439 pictures\n",
      "processed 440 pictures\n",
      "processed 441 pictures\n",
      "processed 442 pictures\n",
      "processed 443 pictures\n",
      "processed 444 pictures\n",
      "processed 445 pictures\n",
      "processed 446 pictures\n",
      "processed 447 pictures\n",
      "processed 448 pictures\n",
      "processed 449 pictures\n",
      "processed 450 pictures\n",
      "processed 451 pictures\n",
      "processed 452 pictures\n",
      "processed 453 pictures\n",
      "processed 454 pictures\n",
      "processed 455 pictures\n",
      "processed 456 pictures\n",
      "processed 457 pictures\n",
      "processed 458 pictures\n",
      "processed 459 pictures\n",
      "processed 460 pictures\n",
      "processed 461 pictures\n",
      "processed 462 pictures\n",
      "processed 463 pictures\n",
      "processed 464 pictures\n",
      "processed 465 pictures\n",
      "processed 466 pictures\n",
      "processed 467 pictures\n",
      "processed 468 pictures\n",
      "processed 469 pictures\n",
      "processed 470 pictures\n",
      "processed 471 pictures\n",
      "processed 472 pictures\n",
      "processed 473 pictures\n",
      "processed 474 pictures\n",
      "processed 475 pictures\n",
      "processed 476 pictures\n",
      "processed 477 pictures\n",
      "processed 478 pictures\n",
      "processed 479 pictures\n",
      "测试\n"
     ]
    }
   ],
   "source": [
    "!python predict_all.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### predict.py\n",
    "* 用保存的yolo_epoch199.pdparams模型进行预测效果，图片选用dataset/test_A/images/00100.jpg，输出为output_pic.png，我们可以看到模型识别并标注了井盖、指示箭头图框。\n",
    "* 该模型经过200轮训练，能够在置信度30%以上检测出多个特征边框。\n",
    "* 由于对yolov3还没有吃透，目前检测出来是在mean、anchors等方面可以改，但也不知道效果如何。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py:107: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import MutableMapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable, Mapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sized\n",
      "W0705 11:18:07.161103  1311 device_context.cc:404] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 10.1\n",
      "W0705 11:18:07.165459  1311 device_context.cc:422] device: 0, cuDNN Version: 7.6.\n",
      "[array([[0.00000000e+00, 6.95396140e-02, 6.20561096e+02, 9.87185547e+02,\n",
      "        7.57663513e+02, 1.18300000e+03],\n",
      "       [0.00000000e+00, 4.31646891e-02, 6.56351807e+02, 8.00225830e+02,\n",
      "        7.95654419e+02, 1.09719849e+03],\n",
      "       [1.00000000e+00, 9.99521673e-01, 1.13288196e+03, 5.96665833e+02,\n",
      "        1.26457605e+03, 6.30091003e+02],\n",
      "       [1.00000000e+00, 9.97465611e-01, 1.03034131e+03, 4.96760437e+02,\n",
      "        1.15006543e+03, 5.33629211e+02],\n",
      "       [4.00000000e+00, 2.11162746e-01, 6.56351807e+02, 8.00225830e+02,\n",
      "        7.95654419e+02, 1.09719849e+03],\n",
      "       [4.00000000e+00, 4.46288884e-02, 6.20561096e+02, 9.87185547e+02,\n",
      "        7.57663513e+02, 1.18300000e+03],\n",
      "       [4.00000000e+00, 3.10880616e-02, 1.12215247e+03, 6.20368164e+02,\n",
      "        1.29374231e+03, 8.57155762e+02],\n",
      "       [5.00000000e+00, 9.58090574e-02, 1.12215247e+03, 6.20368164e+02,\n",
      "        1.29374231e+03, 8.57155762e+02],\n",
      "       [6.00000000e+00, 1.00529296e-02, 6.56351807e+02, 8.00225830e+02,\n",
      "        7.95654419e+02, 1.09719849e+03]])]\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/cbook/__init__.py:2349: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  if isinstance(obj, collections.Iterator):\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/cbook/__init__.py:2366: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  return list(data) if isinstance(data, collections.MappingView) else data\n",
      "Figure(1000x1000)\n"
     ]
    }
   ],
   "source": [
    "! python predict.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 六、后期规划\n",
    "* 　模型参数需要优化；　　\n",
    "* \t端到端部署流程熟悉应用；\n",
    "* 　yolov3里面get_loss_self等函数消化实现。。。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
